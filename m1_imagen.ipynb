{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxCkB_DXTHzf"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hny4I-ODTIS6"
   },
   "source": [
    "# Image Generation with Imagen on Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_generation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_generation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/image_generation.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nLS57E2TO5y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Imagen on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/image/overview) brings Google's state of the art generative AI capabilities to application developers. With Imagen on Vertex AI, application developers can build next-generation AI products that transform their user's imagination into high quality visual assets, in seconds.\n",
    "\n",
    "With Imagen, you can do the following:\n",
    "- Generate novel images using only a text prompt (text-to-image generation).\n",
    "- Edit an entire uploaded or generated image with a text prompt.\n",
    "- Edit only parts of an uploaded or generated image using a mask area you define.\n",
    "- Upscale existing, generated, or edited images.\n",
    "- Fine-tune a model with a specific subject (for example, a specific handbag or shoe) for image generation.\n",
    "- Get text descriptions of images with visual captioning.\n",
    "- Get answers to a question about an image with Visual Question Answering (VQA).\n",
    "\n",
    "This notebook focuses on **image generation** only. You can read more about image generation feature from Imagen [here](https://cloud.google.com/vertex-ai/docs/generative-ai/image/generate-images).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXsvgIuwTPZw"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, you will be exploring the image generation features of Imagen using the Vertex AI Python SDK. You will\n",
    "\n",
    "- generate images using text prompts\n",
    "- experiment with different parameters, such as:\n",
    "    - increasing the number of images to be generated\n",
    "    - fixing a seed number for reproducibility\n",
    "    - influencing the output images using negative prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skXAu__iqks_"
   },
   "source": [
    "### Costs\n",
    "\n",
    "- This notebook uses billable components of Google Cloud:\n",
    "  - Vertex AI (Imagen)\n",
    "\n",
    "- Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvKl-BtQTRiQ"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwFMpIMrTV_4"
   },
   "source": [
    "### Install Vertex AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYUu8VMdJs3V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --quiet --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "4ea24b14-a08b-4165-b05a-3b01b0604607",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhfneknwEDHT"
   },
   "source": [
    "### Load the image generation model\n",
    "\n",
    "The model names from Vertex AI Imagen have two components: model name and version number. The naming convention follow this format: `<model-name>@<version-number>`. For example, `imagegeneration@001` represent the version **001** of the **imagetext** model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEKPNLNL5RhD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "\n",
    "generation_model = ImageGenerationModel.from_pretrained(\"imagegeneration@006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLZagQ8NUDiB"
   },
   "source": [
    "### Generate an image\n",
    "\n",
    "The `generate_image` function can be used to generate images. All you need is a text prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GYBwQuciCco",
    "outputId": "388918cb-ae4b-4619-a9f7-2e62d5ad2eeb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"A beautiful ice princess with silver hair, fantasy concept art style\"\n",
    "\n",
    "response = generation_model.generate_images(\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "response.images[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZy8fNc5_HnY"
   },
   "source": [
    "Now, you have the power to generate the image you desire. Here are some example prompts to inspire you:\n",
    "- A raccoon wearing formal clothes, wearing a top hat. Oil painting in the style of Vincent Van Gogh.\n",
    "- A digital collage of famous works of art, all blended together into one cohesive image.\n",
    "- A whimsical scene from a children's book, such as a tea party with talking animals.\n",
    "- A futuristic cityscape with towering skyscrapers and flying cars.\n",
    "- A studio photo of a modern armchair, dramatic lighting, warm.\n",
    "- A surreal landscape of a city made of ice and snow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SACmbbUb_MHX",
    "outputId": "e31f6926-04ad-403d-85bd-6e6adbf2804d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"A futuristic cityscape with towering skyscrapers and flying cars.\"  # @param {type:\"string\"}\n",
    "\n",
    "response = generation_model.generate_images(prompt=prompt)\n",
    "\n",
    "response.images[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RuVUB6MVGa-"
   },
   "source": [
    "###  Explore different parameters\n",
    "\n",
    "The `generate_images` function accepts additional parameters that can be used to influence the generated images. The following sections will explore how to influence the output images through the use of those additional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbYtoZtTB98_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# An axuillary function to display images in grid\n",
    "def display_images_in_grid(images):\n",
    "    \"\"\"Displays the provided images in a grid format. 4 images per row.\n",
    "\n",
    "    Args:\n",
    "        images: A list of PIL Image objects representing the images to display.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the number of rows and columns for the grid layout.\n",
    "    nrows = math.ceil(len(images) / 4)  # Display at most 4 images per row\n",
    "    ncols = min(len(images) + 1, 4)  # Adjust columns based on the number of images\n",
    "\n",
    "    # Create a figure and axes for the grid layout.\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(images):\n",
    "            # Display the image in the current axis.\n",
    "            ax.imshow(images[i]._pil_image)\n",
    "\n",
    "            # Adjust the axis aspect ratio to maintain image proportions.\n",
    "            ax.set_aspect(\"equal\")\n",
    "\n",
    "            # Disable axis ticks for a cleaner appearance.\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        else:\n",
    "            # Hide empty subplots to avoid displaying blank axes.\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    # Adjust the layout to minimize whitespace between subplots.\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the figure with the arranged images.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--0bCzEYB-uF"
   },
   "source": [
    "#### number_of_images\n",
    "\n",
    "You can use the `number_of_images` parameter to generate up to eight images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "_9dPZC4VGISm",
    "outputId": "88c24f30-4e7a-4107-a732-3807b0bd03d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"a delicious bowl of pho from Vietnam\"\n",
    "\n",
    "response = generation_model.generate_images(\n",
    "    prompt=prompt,\n",
    "    number_of_images=4,\n",
    ")\n",
    "\n",
    "display_images_in_grid(response.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkQGTuaobR-5"
   },
   "source": [
    "Try running the code a few time and observe the generate images. You will notice that the model generates a new set of images each time, even though the same prompt is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dg0D2VcfQPH3"
   },
   "source": [
    "#### seed\n",
    "\n",
    "With the `seed` parameter, you can influence the model to create the same output from the same input every time. Please note that the order of the generated images may still change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "CPoUULlZHJNI",
    "outputId": "f4801149-b09f-4a61-e2fc-dba0283f84cd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = generation_model.generate_images(\n",
    "    prompt=prompt,\n",
    "    number_of_images=4,\n",
    "    add_watermark=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "display_images_in_grid(response.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "9kvARikDRYiZ",
    "outputId": "426174d5-f7ff-4a71-e22e-4acd09893857",
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = generation_model.generate_images(\n",
    "    prompt=prompt,\n",
    "    number_of_images=4,\n",
    "    add_watermark=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "display_images_in_grid(response.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbuHaMy8ak_5"
   },
   "source": [
    "As can be observed, the model produced an identical set of images after utilizing the seed parameter, although the order of the images varies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihdvSoN2bn0b"
   },
   "source": [
    "#### negative_prompt\n",
    "\n",
    "Objects you do not want to generate can be excluded using the `negative_prompt` parameter. \"Bean sprout\" was given as a negative prompt in the example below. As a result, despite using the same prompt and seed number, the model did not produce bean sprout in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "Dt6zoj7hX4me",
    "outputId": "6581a374-3c98-4c2c-fd94-a5da8d1136f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = generation_model.generate_images(\n",
    "    prompt=prompt,\n",
    "    number_of_images=4,\n",
    "    add_watermark=False,\n",
    "    seed=42,\n",
    "    negative_prompt=\"bean sprout\",\n",
    ")\n",
    "\n",
    "display_images_in_grid(response.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sk0eXjQ1nR4F"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "You have explored the Imagen's image generation features through the Vertex AI Python SDK, including the additional parameters that influence image generation. The next step is to enhance your skills by exploring this [prompting guide](https://cloud.google.com/vertex-ai/docs/generative-ai/image/img-gen-prompt-guide?_ga=2.128324367.-2094800479.1701746552&_gac=1.219926379.1701161688.CjwKCAiAvJarBhA1EiwAGgZl0LFQUFOFZUxfNPlzjB4T00PDiLeCIEYfY-coLbX9eUfHKr_i8VbtSBoCEJQQAvD_BwE). Through practice, you will become proficient in the art of image prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hny4I-ODTIS6"
   },
   "source": [
    "# Visual captioning with Imagen on Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_captioning.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_captioning.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_captioning.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nLS57E2TO5y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Imagen on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/image/overview) (image Generative AI) offers a variety of features:\n",
    "- Image generation\n",
    "- Image editing\n",
    "- Visual captioning\n",
    "- Visual question answering\n",
    "\n",
    "This notebook focuses on **visual captioning** only.\n",
    "\n",
    "[Visual captioning with Imagen on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/image/image-captioning) can generate text descriptions of images. The model takes in an image as input and produces one or more text descriptions of the image as output. The generated text descriptions can be used for a variety of use cases:\n",
    "- getting detailed metadata about images for storing and searching\n",
    "- generating automated captioning to support accessibility use cases\n",
    "- producing descriptions of products and visual assets\n",
    "\n",
    "More information about Visual captioning with Imagen on  Vertex AI can be found in the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/image/image-captioning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXsvgIuwTPZw"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, you will learn how to use the Vertex AI Python SDK to:\n",
    "\n",
    "- Generate image captions using the Imagen's visual captioning features\n",
    "\n",
    "- Experiment with different parameters, such as:\n",
    "    - number of captions to be generated\n",
    "    - language of the generated captions\n",
    "    - type and version of model that is used to generate the captions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skXAu__iqks_"
   },
   "source": [
    "### Costs\n",
    "\n",
    "- This notebook uses billable components of Google Cloud:\n",
    "  - Vertex AI (Imagen)\n",
    "\n",
    "- Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvKl-BtQTRiQ",
    "tags": []
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhfneknwEDHT"
   },
   "source": [
    "### Load the image captioning model\n",
    "\n",
    "The model names from Vertex AI Imagen have two components: model name and version number. The naming convention follow this format: `<model-name>@<version-number>`. For example, `imagetext@001` represent the version **001** of the **imagetext** model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuEbYyfM4RR7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import ImageCaptioningModel\n",
    "\n",
    "image_captioning_model = ImageCaptioningModel.from_pretrained(\"imagetext@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zoPQnQoED10"
   },
   "source": [
    "### Load the image file\n",
    "\n",
    "To use the visual captioning model, you first need to create an `Image` class using the image file. The model only accepts `Image` class objects, so this is a necessary step before you can generate captions.\n",
    "\n",
    "Moreover, [Visual Captioning with Imagen](https://cloud.google.com/vertex-ai/docs/generative-ai/image/image-captioning) only accepts specific image file formats (e.g. PNG, JPEG), and may have file size is limitations (e.g. 10 MB). You can find out specific details from [this official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/image/image-captioning#img-cap-rest).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S00UD6_aldHy",
    "outputId": "18252c1c-7c89-455e-9e55-6e17ce60a340",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download an image from Google Cloud Storage\n",
    "! gsutil cp \"gs://github-repo/img/vision/google-cloud-next.jpeg\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "xnH-MARxgGrX",
    "outputId": "9db52521-b56d-4ed9-ba3d-abb3f1701d4d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import Image\n",
    "\n",
    "# Load the image file as Image object\n",
    "cloud_next_image = Image.load_from_file(\"google-cloud-next.jpeg\")\n",
    "cloud_next_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYjS3nL5LTbY"
   },
   "source": [
    "###  Generate captions from the image\n",
    "\n",
    "In this section, you will use the visual captioning model to generate text descriptions of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeBCOavpRl4y",
    "outputId": "12353348-35f1-4a68-eaca-fdac91c9402b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a caption from the image\n",
    "image_captioning_model.get_captions(\n",
    "    image=cloud_next_image,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwBBeYNORmTf"
   },
   "source": [
    "You can generate up to three captions from a single image by changing the `number_of_results` parameter from 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Al6XnFfEgCc4",
    "outputId": "c8093bb7-15b9-43d3-c9bf-f488e28841f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get 3 captions from the image\n",
    "image_captioning_model.get_captions(\n",
    "    image=cloud_next_image,\n",
    "    number_of_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oJ-WiCEUZQp"
   },
   "source": [
    "### Generating captions in non-English languages\n",
    "\n",
    "Visual captioning with Imagen on Vertex AI can generate captions in multiple languages as well. To generate a caption in a specific language, you can set the `language` parameter as one of the values:\n",
    "- `en` - English\n",
    "- `fr` - French\n",
    "- `de` - German\n",
    "- `it` - Italian\n",
    "- `es` - Spanish\n",
    "\n",
    "For a list of supported languages, check out the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/image/image-captioning#languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TilOotKGk9MF",
    "outputId": "fbaa921a-b169-445a-c24c-8462dce19e79",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get 3 image captions in French\n",
    "image_captioning_model.get_captions(\n",
    "    image=cloud_next_image,\n",
    "    number_of_results=3,\n",
    "    language=\"fr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsB8pSS-h7Sw"
   },
   "source": [
    "## Try it yourself\n",
    "\n",
    "You can also try using the visual captioning model with images of your choice. If you need to download an image file, you can use the provided auxiliary function `download_image`.\n",
    "\n",
    "Feel free to experiment with different images and model parameters to see how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgPcf_SEBKKW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    \"\"\"Downloads an image from the specified URL.\"\"\"\n",
    "\n",
    "    # Send a get request to the url\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # If the request is successful\n",
    "    if response.status_code == 200:\n",
    "        # Define image related variables\n",
    "        image_path = os.path.basename(url)\n",
    "        image_bytes = response.content\n",
    "        image_type = response.headers[\"Content-Type\"].split(\"/\")[1]\n",
    "\n",
    "        # Check for image type, currently only PNG or JPEG format are supported\n",
    "        if image_type in (\"png\", \"jpg\", \"jpeg\"):\n",
    "            # Write image data to a file\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "            return image_path\n",
    "        else:\n",
    "            raise Exception(\"Image can only be in PNG or JPEG format\")\n",
    "\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bm5Nt9Yj6N88",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download an image\n",
    "url = \"https://t4.ftcdn.net/jpg/02/84/85/61/360_F_284856166_H5l84ry1V186YgMzZMXB0bhfJZTYAGCH.jpg\"\n",
    "download_image(url)\n",
    "\n",
    "image_path = \"360_F_284856166_H5l84ry1V186YgMzZMXB0bhfJZTYAGCH.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "eBN2j384jPbm",
    "outputId": "d0b3c0d0-89d5-45e7-8637-410f0bcd0096",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the newly downloaded image\n",
    "user_image = Image.load_from_file(image_path)\n",
    "user_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilm66OqkVneT",
    "outputId": "13abddb1-913f-42bb-df43-f2b4226b8faf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the visual captions for the image\n",
    "image_captioning_model.get_captions(\n",
    "    image=user_image,\n",
    "    number_of_results=3,\n",
    "    language=\"en\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hny4I-ODTIS6"
   },
   "source": [
    "# Visual Question Answering (VQA) with Imagen on Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_question_answering.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_question_answering.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_question_answering.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nLS57E2TO5y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Imagen on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/image/overview) (image Generative AI) offers a variety of features:\n",
    "- Image generation\n",
    "- Image editing\n",
    "- Visual captioning\n",
    "- Visual question answering\n",
    "\n",
    "This notebook focuses on **visual question answering** only.\n",
    "\n",
    "[Visual question answering (VQA) with Imagen](https://cloud.google.com/vertex-ai/docs/generative-ai/image/visual-question-answering) can understand the content of an image and answer questions about it. The model takes in an image and a question as input, and then using the image as context to produce one or more answers to the question.\n",
    "\n",
    "The visual question answering (VQA) can be used for a variety of use cases, including:\n",
    "- assisting the visually impaired to gain more information about the images\n",
    "- answering customer questions about products or services in the image\n",
    "- creating interactive learning environment and providing interactive learning experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXsvgIuwTPZw"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this notebook, you will learn how to use the Vertex AI Python SDK to:\n",
    "\n",
    "- Answering questions about images using the Imagen's visual question answering features\n",
    "\n",
    "- Experiment with different parameters, such as:\n",
    "    - number of answers to be provided by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skXAu__iqks_"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "- Vertex AI (Imagen)\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvKl-BtQTRiQ"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhfneknwEDHT"
   },
   "source": [
    "### Load the image question answering model\n",
    "\n",
    "The model names from Vertex AI Imagen have two components: model name and version number. The naming convention follow this format: `<model-name>@<version-number>`. For example, `imagetext@001` represents the version **001** of the **imagetext** model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuEbYyfM4RR7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import ImageQnAModel\n",
    "\n",
    "image_qna_model = ImageQnAModel.from_pretrained(\"imagetext@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zoPQnQoED10"
   },
   "source": [
    "### Load the image file\n",
    "\n",
    "To use the image question answering model, you first need to create an `Image` class using the image file. The model only accepts `Image` class objects, so this is a necessary step before you can ask questions.\n",
    "\n",
    "\n",
    "Addtinally, [Visual Question Answering with Imagen](https://cloud.google.com/vertex-ai/docs/generative-ai/image/visual-question-answering#img-vqa-rest) only accepts specific image file formats (e.g. PNG, JPEG), and may have file size is limitations (e.g. 10 MB). You can find out specific details from the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/image/visual-question-answering#img-vqa-rest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 777
    },
    "id": "xnH-MARxgGrX",
    "outputId": "682e6b8d-6c9f-4464-992e-2f15e1a6485b"
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import Image\n",
    "\n",
    "# Load the image file as Image object\n",
    "cloud_next_image = Image.load_from_file(\"google-cloud-next.jpeg\")\n",
    "cloud_next_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYjS3nL5LTbY"
   },
   "source": [
    "### Ask questions about the image\n",
    "\n",
    "Now ask questions about the image using the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3FliDlsm6ah",
    "outputId": "ac01f0bb-31c0-481b-e211-73e06c413897",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask a question about the image\n",
    "image_qna_model.ask_question(\n",
    "    image=cloud_next_image, question=\"What is happening in this image?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVFKttepEPB9",
    "outputId": "3e16b46e-2761-48aa-dba1-467b3a0b583d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask a follow up question about the image\n",
    "image_qna_model.ask_question(\n",
    "    image=cloud_next_image, question=\"What are the people in the image doing?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwBBeYNORmTf"
   },
   "source": [
    "You can get up to three answers from a single image by changing the `number_of_results` parameter from 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1GJwlZUt4-E",
    "outputId": "f3fbdf53-d7f8-4363-c704-af357944257d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get 3 answers from the image\n",
    "image_qna_model.ask_question(\n",
    "    image=cloud_next_image,\n",
    "    question=\"What are the people in the image doing?\",\n",
    "    number_of_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0FVAjg-okiW"
   },
   "source": [
    "## Try it yourself\n",
    "\n",
    "You can also try using the visual question answering model with images of your choice. If you need to download an image file, you can use the provided auxiliary function `download_image`.\n",
    "\n",
    "Feel free to experiment with different images and model parameters to see how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ll8KFbCujQ9y",
    "outputId": "1d412537-34dc-418b-a74a-cef379dfb79f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download an image\n",
    "url = \"https://storage.googleapis.com/gweb-cloudblog-publish/images/GettyImages-871168786.max-2600x2600.jpg\"\n",
    "image_path = download_image(url)\n",
    "\n",
    "# Load the newly downloaded image\n",
    "user_image = Image.load_from_file(image_path)\n",
    "user_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9g6DsfKWo5S-",
    "outputId": "a3822c37-2062-4f89-c667-e2027b062ffd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask a question about the image\n",
    "image_qna_model.ask_question(\n",
    "    image=user_image,\n",
    "    question=\"What is happening in this photo?\",\n",
    "    number_of_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YC90LG50Fcru",
    "outputId": "63dcd584-1f95-4086-bc72-8b43e8d2e8ec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask a question about the image\n",
    "image_qna_model.ask_question(\n",
    "    image=user_image,\n",
    "    question=\"What advertising channels would this image be suitable for?\",\n",
    "    number_of_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydXxZJvLKvtI",
    "outputId": "d51144c0-09b0-4b10-c7ff-0edc0fe3f40f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask a question about the image\n",
    "image_qna_model.ask_question(\n",
    "    image=user_image,\n",
    "    question=\"What type of insects could live in this area?\",\n",
    "    number_of_results=3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
