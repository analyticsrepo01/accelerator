{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272dd5b9-d0b9-49a6-aac3-7e97b4a15aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a839f5-bbb4-4df4-b372-362e1ce2d5aa",
   "metadata": {},
   "source": [
    "# Building Agents - Email Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd289544-3724-4da6-9aed-6bc2eeb3a123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --quiet -U 'crewai[tools]' mdpdf \n",
    "%pip install --upgrade --quiet  langchain-core langchain-google-vertexai\n",
    "%pip install --quiet -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b5ffd-d89c-4c8b-8772-06fcef3e2b9c",
   "metadata": {},
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955bb2db-e758-436e-ba33-ef0550f94a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "import time\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ca56a-f6ea-4098-a24a-f2cbf25a3acc",
   "metadata": {},
   "source": [
    "### Import libraries and intialize Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6d08f-8915-47df-bb86-99a1cce9b091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"asia-southeast1\"\n",
    "\n",
    "FOLDER_NAME=\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b19850-3565-46ec-9db0-2757427ec449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import tool\n",
    "# from langchain_vertexai import ChatGemini\n",
    "from crewai_tools.tools import FileReadTool\n",
    "import os, requests, re, mdpdf, subprocess\n",
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import uuid, os\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-pro\", # Replace with your desired Gemini model\n",
    "    project_id=os.getenv(PROJECT_ID), # Your Vertex AI project ID\n",
    "    location=\"us-central1\", # Your Vertex AI location\n",
    ")\n",
    "\n",
    "\n",
    "def generate_pro(input_prompt):\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    full_prompt = '''summarize the prompt below and do note prompt below will be send to imagen mode so please clean up any sensitve words and replace them into unblocked words like replace girl or lady can be replaced by female human and so on : ''' + input_prompt\n",
    "    responses = model.generate_content(\n",
    "    input_prompt,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 8190,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 1\n",
    "    },stream=False,)\n",
    "    \n",
    "    # print (responses.text)\n",
    "    \n",
    "    return(responses.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f68d1-5beb-43e6-8653-626b5212b4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "# from langchain_groq import ChatGroq\n",
    "from langchain.agents import  Tool\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9abe26-f7fb-4a5d-888d-b5fcccd5ab3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"This is a conversation between a human and ai agent:\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Write a summary of the conversation for {input}:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"input\", \"chat_history\"], template=template)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "readonlymemory = ReadOnlySharedMemory(memory=memory)\n",
    "summary_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=readonlymemory,  # use the read-only memory to prevent the tool from modifying the memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67a0f1-c947-4d33-bcc9-ae09976ee032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create searches\n",
    "search =  DuckDuckGoSearchRun()\n",
    "\n",
    "tool_use = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Summary\",\n",
    "        func=summary_chain.run,\n",
    "        description=\"useful for when you summarize a conversation. The input to this tool should be a string, representing who will read this summary.\",\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "tool_use_1 = [\n",
    "    Tool(\n",
    "        name=\"Summary\",\n",
    "        func=summary_chain.run,\n",
    "        description=\"useful for when you summarize a conversation. The input to this tool should be a string, representing who will read this summary.\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662602f0-ef14-4f15-9d2f-9d5dbcea84df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Agents\n",
    "email_author = Agent(\n",
    "    role='Professional Email Author',\n",
    "    goal='Craft concise and engaging emails',\n",
    "    backstory='Experienced in writing impactful marketing emails.',\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    "    tools=tool_use\n",
    ")\n",
    "marketing_strategist = Agent(\n",
    "    role='Marketing Strategist',\n",
    "    goal='Lead the team in creating effective cold emails',\n",
    "    backstory='A seasoned Chief Marketing Officer with a keen eye for standout marketing content.',\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    "    llm=llm,\n",
    "    tools=tool_use_1\n",
    ")\n",
    "\n",
    "content_specialist = Agent(\n",
    "    role='Content Specialist',\n",
    "    goal='Critique and refine email content',\n",
    "    backstory='A professional copywriter with a wealth of experience in persuasive writing.',\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    "    tools=tool_use_1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c2767-1143-4c8e-b8ce-e79af72ce395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Task\n",
    "email_task = Task(\n",
    "    description='''1. Generate two distinct variations of a cold email promoting a video editing solution. \n",
    "    2. Evaluate the written emails for their effectiveness and engagement.\n",
    "    3. Scrutinize the emails for grammatical correctness and clarity.\n",
    "    4. Adjust the emails to align with best practices for cold outreach. Consider the feedback \n",
    "    provided to the marketing_strategist.\n",
    "    5. Revise the emails based on all feedback, creating two final versions.''',\n",
    "    agent=marketing_strategist , # The Marketing Strategist is in charge and can delegate\n",
    "    expected_output='A structured email accourding to the instructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d72ea0-7391-42fe-a22e-fb5996671a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Single Crew\n",
    "email_crew = Crew(\n",
    "    agents=[email_author, marketing_strategist, content_specialist],\n",
    "    tasks=[email_task],\n",
    "    verbose=True,\n",
    "    process=Process.sequential\n",
    ")\n",
    "\n",
    "# Execution Flow\n",
    "print(\"Crew: Working on Email Task\")\n",
    "emails_output = email_crew.kickoff()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
